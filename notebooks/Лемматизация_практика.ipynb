{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSF5uS39evpMZyIiL4uoh8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnnSenina/Python_FLAS_2025/blob/main/notebooks/%D0%9B%D0%B5%D0%BC%D0%BC%D0%B0%D1%82%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F_%D0%BF%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%BA%D0%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 1\n",
        "\n",
        "Завершите все этапы предобработки текста до лемматизации\n",
        "\n",
        "Важно! Тексты не на русском, а значит, pymorphy и mystem не подойдут.\n",
        "\n",
        "Почти для всех задач подойдет, например, [spaCy](https://spacy.io/usage/models#quickstart)"
      ],
      "metadata": {
        "id": "nuqK1QSRcO1u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REj671X-cE19"
      },
      "outputs": [],
      "source": [
        "# снова рыбка-бананка Сэлинджера, но на английском - spaCy\n",
        "text = '''THERE WERE ninety-seven New-York advertising men in the hotel, and, the way they were monopolizing the long-distance lines, the girl in 507 had to wait from noon till almost two-thirty to get her call through. She used the time, though. She read an article in a women's pocket-size magazine, called \"Sex Is Fun-or Hell.\" She washed her comb and brush. She took the spot out of the skirt of her beige suit. She moved the button on her Saks blouse. She tweezed out two freshly surfaced hairs in her mole. When the operator finally rang her room, she was sitting on the window seat and had almost finished putting lacquer on the nails of her left hand.\n",
        "She was a girl who for a ringing phone dropped exactly nothing. She looked as if her phone had been ringing continually ever since she had reached puberty.\n",
        "With her little lacquer brush, while the phone was ringing, she went over the nail of her little finger, accentuating the line of the moon. She then replaced the cap on the bottle of lacquer and, standing up, passed her left--the wet--hand back and forth through the air. With her dry hand, she picked up a congested ashtray from the window seat and carried it with her over to the night table, on which the phone stood. She sat down on one of the made-up twin beds and--it was the fifth or sixth ring--picked up the phone.'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# установка spaCy, модель для английского:\n",
        "!python -m spacy download en_core_web_sm\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()"
      ],
      "metadata": {
        "id": "xWtOk5BSc3w9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# стоп-слова из nltk:\n",
        "import nltk\n",
        "from nltk import download\n",
        "download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "en_stop_words = stopwords.words('english')"
      ],
      "metadata": {
        "id": "pg0v8pczc3nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(stopwords.fileids())"
      ],
      "metadata": {
        "id": "91qPOPkYT-Oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# я поменяла функцию таким образом, чтобы она просила у вас список стоп-слов в качестве аргумента\n",
        "\n",
        "def lemm_spacy(text, stop_words):\n",
        "  doc = nlp(text)\n",
        "  lem_list = [word.lemma_.lower() for word in doc if word.lemma_ not in stop_words and word.lemma_[0].isalpha()]\n",
        "  return lem_list"
      ],
      "metadata": {
        "id": "oBvsvyFpO-Rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(lemm_spacy(text, en_stop_words))"
      ],
      "metadata": {
        "id": "fH64pskDPPb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вариант чуть лучше:\n",
        "* сначала токенизировать nltk (обратите внимание на Нью-Йорк), потом склеить обратно через join, потом передать в spaCy;\n",
        "* расширить список стоп-слов и т.д.\n",
        "\n"
      ],
      "metadata": {
        "id": "Pi9dHurjRG7i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Быстрый старт в [spaCy](https://spacy.io/usage/models#quickstart), тренируемся"
      ],
      "metadata": {
        "id": "P2l0TtgvR1s2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# текст на польском - spaCy\n",
        "text = '''Mieszkam w środku Europy – w Polsce. Ale w którym mieście mieszkam? Poniżej przedstawię kilka podpowiedzi które powinny ułatwić rozwiązanie tej zagadki.\n",
        "Moje miasto jest czwarte w Polsce pod względem liczby ludności. Znajdziesz w nim miejsca, które nazywają się tak samo jak inne miejsca na świecie – np. Kilimandżaro albo Morskie Oko. Znana jest też Fontanna Multimedialna umieszczona obok Hali Stulecia.\n",
        "Jeszcze kilkadziesiąt lat temu miasto nie należało do Polski. Moje miasto ma mnóstwo mostów, rzek oraz wysp i wysepek. W moim mieście znajdziecie też fosę, która cały czas działa i w której cały czas jest woda. Z mojego miasta bliżej jest do stolicy Niemiec – Berlina niż do stolicy Polski – Warszawy.\n",
        "Miasto jest bardzo lubiane przez turystów – każdego roku miliony z nich chodzą po ulicach miasta. Wielu z nich odwiedza nasze słynne ZOO. Bardzo popularne w nim jest Afrykarium, w którym możliwe jest oglądanie wielu zwierząt w prawie naturalnych warunkach.\n",
        "Dla miłośników kultury miasto oferuje liczne teatry, kina i muzea. Miasto zostało wybrane Europejską Stolicą Kultury 2016 i Światową Stolicą Książki 2016.\n",
        "Czy wystarczy już tych podpowiedzi? Jeśli nie – to jeszcze ostatnia: łacińska nazwa mojego miasta to Vratislavia, a niemiecka to Breslau. Czy już znasz odpowiedź? Tak, to Wrocław!'''"
      ],
      "metadata": {
        "id": "-GndRbqAcNoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# стоп-слов на польском нет в nltk - ищем в другом месте, например:\n",
        "!pip install stop-words\n",
        "from stop_words import get_stop_words\n",
        "pl_stop_words = get_stop_words('polish')\n",
        "print(pl_stop_words)"
      ],
      "metadata": {
        "id": "00pV6YCuUuOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# подгрузите модель для польского из spaCy\n"
      ],
      "metadata": {
        "id": "9aso2Lw5c4Vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# лемматизируйте\n"
      ],
      "metadata": {
        "id": "__LYdxeMc4O8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Возможное решение:"
      ],
      "metadata": {
        "id": "BsJoMmMHRpmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "!python -m spacy download pl_core_news_sm\n",
        "import spacy\n",
        "nlp = spacy.load(\"pl_core_news_sm\")\n",
        "import pl_core_news_sm\n",
        "nlp = pl_core_news_sm.load()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kOoBpT1FRpQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "' '.join(lemm_spacy(text, pl_stop_words))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xUYX_MMGWA0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание со звездочкой: тот же самый текст на польском, но теперь [Stanza](https://stanfordnlp.github.io/stanza/)\n",
        "\n",
        "Найдите, как подгрузить модель на сайте, и примените (обозначение польского - pl):"
      ],
      "metadata": {
        "id": "DJcWisl2WSwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# тот же самый текст на польском, но теперь Stanza:\n",
        "# установите библиотеку\n",
        "!pip install stanza\n",
        "\n",
        "# загрузите модель для польского с ее сайта:\n"
      ],
      "metadata": {
        "id": "5QCcxoi1uT9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "О лемматизации - [здесь](https://stanfordnlp.github.io/stanza/lemma.html)"
      ],
      "metadata": {
        "id": "yxklO8TLXeVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# скопируйте команды по лемматизации и посмотрите на результат\n"
      ],
      "metadata": {
        "id": "5f4pVi8eZPwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# возможно ли это очистить от пунктуации, стоп-слов и склеить?\n"
      ],
      "metadata": {
        "id": "XHBDzuY4uozA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Возможное решение:"
      ],
      "metadata": {
        "id": "wzHy82mfW5Kq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import stanza\n",
        "stanza.download('pl')\n",
        "nlp = stanza.Pipeline('pl')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AYmpdgXhW7Hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "doc = nlp(text)\n",
        "# можно еще здесь добавить приведение к нижнему регистру, но я не стала (обратите внимание на геогр.названия далее)\n",
        "\n",
        "# из документации библиотеки:\n",
        "print(*[f'word: {word.text+\" \"}\\tlemma: {word.lemma}' for sent in doc.sentences for word in sent.words], sep='\\n')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "liFiqBmOX2u1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# вариант, чистящий от стоп-слов и пунктуации и склеивающий леммы обратно в текст\n",
        "lemm = [word.lemma for sent in doc.sentences for word in sent.words \\\n",
        "        if word.lemma not in pl_stop_words and word.lemma[0].isalpha()]\n",
        "\n",
        "' '.join(lemm)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "i0J5QmjXYOY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Пример](https://github.com/ann-zh-bk/Aozora_corpus) с японским в проекте в прошлом году"
      ],
      "metadata": {
        "id": "svilWmr9gYIk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Китайский: ~я ничего не понимаю в нем, поэтому~\n",
        "* [Chinese and Arabic Segmenter](https://stanfordnlp.github.io/CoreNLP/tools_segmenter.html) от CoreNPL\n",
        "* [WordSegmenterModel](https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/training/chinese/word-segmentation/WordSegmenter_train_chinese_segmentation.ipynb) от Spark NLP\n",
        "* [Статья на Медиуме](https://towardsdatascience.com/chinese-natural-language-pre-processing-an-introduction-995d16c2705f) (может потребовать VPN) о предобработке китайского модулем jieba"
      ],
      "metadata": {
        "id": "IlVJPr3SgkKf"
      }
    }
  ]
}
